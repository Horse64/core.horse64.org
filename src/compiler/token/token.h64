## @module compiler.token
# Copyright (c) 2020-2025, ellie/@ell1e & Horse64's contributors
# (see AUTHORS.md).
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#
# Alternatively, at your option, this file is offered under the Apache 2
# license, see accompanied LICENSE.md.

import bignum from core.horse64.org
import io from core.horse64.org
import limit from core.horse64.org
import math from core.horse64.org
import net from core.horse64.org
import net.fetch from core.horse64.org
import text from core.horse64.org
import textfmt from core.horse64.org
import uri from core.horse64.org

import compiler.ast.call_or_assign_stmt as call_or_assign_stmt
import compiler.ast.func_stmt as func_stmt
import compiler.limit as climit
import compiler.msg as msg
import compiler.preprocessor as preprocessor
import compiler.project as project
import compiler.typeinfo.ast_typeref as ast_typeref

const _math_ops_single_char = {
    "+", "/", "*", "-", "^", "&",
    "|", "~", "%",
}

const math_ops = (
    _math_ops_single_char + {"^^", "<<", ">>"}
)

const math_assign_ops = {
    "+=", "/=", "*=", "-=", "^=", "&=",
    "|=", "^^=", "~=", "<<=", ">>=",
}

const compare_ops = {
    ">", "<", ">=", "<=", "!=", "=="
}

const bool_compare_ops = {
    "and", "or", "not"
}

const _math_or_comp_starter_chars = (
    _math_ops_single_char + {">", "<", "!"}
)

const _maybe_stmt_token_strs = {
    "while", "do", "func", "for", "with",
    "continue", "break",
    "var", "const", "type", "import", "if",
    "return", "await", "throw",
    "enum", "extend", "struct", "defer"
}

const _maybe_stmt_token_strs_moose64 = {
    "union", "c_import"
}

const _guaranteed_outer_scope_tokens = {
    "type", "import", "enum", "extend"
}

const special_words = {
    # All keywords returned as T_KEYWORD:
    "while", "do", "func", "for", "with",
    "continue", "break",
    "var", "const", "type", "import", "if",
    "return", "await", "later", "rescue",
    "finally", "as", "in", "base", "extend",
    "throw", "any", "from", "protect",
    "repeat", "elseif", "else", "ignore", "enum",
    "struct", "defer",
    # These are not returned as keywords, but still special words:
    "none", "yes", "no", "and", "or", "not", "new",
}

const special_words_moose64_only = {
    "c_import", "failable", "failed",
    "union", "override", "auto_own",
    "packed",
}

func is_maybe_token_str(s, is_moose64=no) {
    if _maybe_stmt_token_strs.has(s) {
        return yes
    }
    if is_moose64 and _maybe_stmt_token_strs_moose64.has(s) {
        return yes
    }
    return no
}

func is_minus_after_this_token_unary(t, is_moose64=no) {
    if t == none or t == "" {
        return yes
    }
    if typename(t) != "str" {
        t = t.str
    }
    if ({"(", "=", "[", ",", "->", ":", "{"}.has(t) or
            (is_special_word(t, is_moose64=is_moose64) and
            not {"yes", "no", "none"}.has(t)) or
            math_assign_ops.has(t) or
            compare_ops.has(t) or
            bool_compare_ops.has(t) or
            math_ops.has(t)) {
        return yes
    }
    return no
}

## @func op_str_to_token_kind
## Return the @{TokenKind} enum value of the corresponding operator
## that has the given string representation. **Warning:** for the
## T_MATH operator `-`, this will always return T_MATH even though
## it might be T_UNARYMATH depending on context.
##
## @param opstr str The string representation of any operator to
##   convert back to the token type.
## @returns TokenKind The corresponding @{TokenKind} value.
func op_str_to_token_kind(opstr) {
    if opstr == "new" {
        return T_NEWOP
    }
    if math_ops.has(opstr) {
        return T_MATH
    }
    if math_assign_ops.has(opstr) {
        return T_MATHASSIGN
    }
    if compare_ops.has(opstr) {
        return T_COMPARE
    }
    if bool_compare_ops.has(opstr) {
        return T_BOOLCOMP
    }
    throw new ValueError("Unknown op str encountered.")
}

## Get the length of a \uHHHH... escaping starting at the
## given offset position in a string literal, or @{none} if
## there isn't one at the given position.
func get_str_widechar_escaping_len(str, pos) {
    func is_hex_digit(c) {
        if c.len < 1 {
            return no
        }
        return (text.code(c) >= text.code("0") and
            text.code(c) <= text.code("9")) or
            (text.code(c) >= text.code("A") and
            text.code(c) <= text.code("F")) or
            (text.code(c) >= text.code("a") and
            text.code(c) <= text.code("f"))
    }
    if pos < 1 or pos + 5 > str.len {
        return none
    }
    if str.sub(pos, pos + 1) != "\\u" {
        return none
    }
    # Determine where the hex digits stop:
    var past_pos = 2
    while past_pos < 10 {
        if past_pos > str.len or
                not is_hex_digit(str.sub(
                    pos + past_pos, pos + past_pos
                )) {
            if past_pos <= 5 {  # Index 2 to 5 must be hex numbers, minimum.
                # (The escape format is \uHHHH to \uHHHHHHHH with all
                # digit amounts in between allowed.)
                return none
            }
            break
        }
        past_pos += 1
    }
    return past_pos
}

## Parse a \uHHHH... escaping starting at the given offset
## position and return the code point as a @{num}, or
## return @{none} if there isn't a valid one starting at
## the given position.
func parse_str_widechar_escaping(str, pos) {
    var escape_len = get_str_widechar_escaping_len(str, pos)
    if escape_len == none {
        # It's not a valid escaping.
        return none
    }
    var hex_part = str.sub(pos + 2, pos + (escape_len - 1))
    assert(hex_part.len >= 4 and hex_part.len <= 8)
    var value = math.parse_hex(hex_part)
    if value > 0x10FFFF {
        return none  # Not a valid code point.
    }
    return value
}

## Parse the \xHH escaping at the given string literal offset
## position, and return the byte value. Returns @{none} if
## there is no valid escaping at the given position.
func parse_str_hex_escaping(str, pos) {
    func is_hex_digit(c) {
        if c.len < 1 {
            return no
        }
        return (text.code(c) >= text.code("0") and
            text.code(c) <= text.code("9")) or
            (text.code(c) >= text.code("A") and
            text.code(c) <= text.code("F")) or
            (text.code(c) >= text.code("a") and
            text.code(c) <= text.code("f"))
    }
    if pos < 1 or pos + 3 > str.len {
        return none
    }
    if str.sub(pos, pos + 1) != "\\x" {
        return none
    }
    if not is_hex_digit(str.sub(pos + 2, pos + 2)) or
            not is_hex_digit(str.sub(pos + 3, pos + 3)) {
        return none
    }
    var value = math.parse_hex(
        str.sub(pos + 2, pos + 3)
    )
    return value
}

## @func parse_token_value
## Parse and return the actual value of a token literal as
## a Horse64 data type. E.g. a T_STR @{token|Token} with its
## @{str attribute|Token.str} set to `'"test\\n"'` will return
## the actual string value `"test\n"`, or for a T_NUM token
## with str attribute `"5"` it will return the @{num value} `5`.
##
## @param tok Token The token to return the value of.
## @returns any The value, with the data type depending on what sort
##   of token it is.
func parse_token_value(tok) {
    func is_hex_digit(c) {
        if c.len < 1 {
            return no
        }
        return (text.code(c) >= text.code("0") and
            text.code(c) <= text.code("9")) or
            (text.code(c) >= text.code("A") and
            text.code(c) <= text.code("F")) or
            (text.code(c) >= text.code("a") and
            text.code(c) <= text.code("f"))
    }
    if tok.kind == T_NUM {
        if tok.str.starts("0x") {
            return math.parse_hex(tok.str)
        }
        return tok.str.to_num()
    } elseif tok.kind == T_BIGNUM {
        throw new TypeError("Cannot return actual "
            "literal value for T_BIGNUM token.")
    } elseif tok.kind == T_STR or
            tok.kind == T_CHARCODE {
        var i = 2
        if tok.kind == T_CHARCODE {
            if tok.str.len < 2 or
                    tok.str[1] != "c" or
                    not {"'", '"'}.has(tok.str[2]) {
                # Invalid literal. Just return empty value.
                return ""
            }
            i = 3
        } else {
            if tok.str.len == 0 or
                    not {"'", '"'}.has(tok.str[1]) {
                # Invalid literal. Just return empty value.
                return ""
            }
        }
        var toklen = tok.str.len
        var escaped = no
        var result = ""
        while i <= toklen - 1 {
            if escaped {
                escaped = no
                if tok.str[i] == "t" {
                    result += "\t"
                } elseif tok.str[i] == "n" {
                    result += "\n"
                } elseif tok.str[i] == "r" {
                    result += "\r"
                } elseif tok.str[i] == "x" {
                    var value = parse_str_hex_escaping(
                        tok.str, i - 1
                    )
                    if value == none {
                        # This is invalid, just skip it.
                        i += 1
                        continue
                    }
                    result += text.from_code(value)
                    i += 3
                    continue
                } elseif tok.str[i] == "u" {
                    var value = parse_str_widechar_escaping(
                        tok.str, i - 1
                    )
                    if value == none {
                        # This is invalid, just skip it.
                        i += 1
                        continue
                    }
                    result += text.from_code(value)
                    i += get_str_widechar_escaping_len(
                        tok.str, i - 1
                    ) - 1
                    continue
                } elseif tok.str[i] == "0" {
                    result += "\0"
                } else {
                    result += tok.str[i]
                }
            } elseif tok.str[i] == "\\" {
                escaped = yes
            } else {
                result += tok.str[i]
            }
            i += 1
        }
        return result
    } elseif tok.kind == T_BYTES {
        if tok.str.len < 2 or
                not {"'", '"'}.has(tok.str[2]) {
            # Invalid literal. Just return empty value.
            return b""
        }
        var toklen = tok.str.len
        var escaped = no
        var result = b""
        var i = 3
        while i <= toklen - 1 {
            if escaped {
                escaped = no
                if tok.str[i] == "t" {
                    result += b"\t"
                } elseif tok.str[i] == "n" {
                    result += b"\n"
                } elseif tok.str[i] == "r" {
                    result += b"\r"
                } elseif tok.str[i] == "x" {
                    var value = parse_str_hex_escaping(
                        tok.str, i - 1
                    )
                    if value == none {
                        # This is invalid, just skip it.
                        i += 1
                        continue
                    }
                    result += text.code_to_bytes(value)
                    i += 3
                    continue
                } elseif tok.str[i] == "u" {
                    var value = parse_str_widechar_escaping(
                        tok.str, i - 1
                    )
                    if value == none {
                        # This is invalid, just skip it.
                        i += 1
                        continue
                    }
                    result += text.code_to_bytes(value)
                    i += get_str_widechar_escaping_len(
                        tok.str, i - 1
                    ) - 1
                    continue
                } elseif tok.str[i] == "0" {
                    result += b"\0"
                } else {
                    result += tok.str[i].as_bytes()
                }
            } elseif tok.str[i] == "\\" {
                escaped = yes
            } else {
                escaped = no
                result += tok.str[i].as_bytes()
            }
            i += 1
        }
        return result
    } elseif tok.kind == T_BOOL {
        return (tok.str == "yes")
    } elseif tok.kind == T_NONE {
        return none
    } else {
        throw new TypeError("Not a basic literal token "
            "with a corresponding Horse64 value.")
    }
}

## @func surely_to_toplevel_even_in_bad_code
## Check whether at the given position, the code should be
## assumed to be at the top level again, the coder having
## e.g. forgotten closing brackets leading up to it.
## @returns bool Returns @{yes} if it's a better idea to
##   assume this is a return to top level even if missing
##   closing brackets, otherwise returns @{no}.
func surely_to_toplevel_even_in_bad_code(
        tokens, start_pos, is_moose64=no
        ) {
    if start_pos >= tokens.len or start_pos < 1 {
        return yes
    }
    if tokens[start_pos].kind == T_KEYWORD and
            ({"type", "import", "enum",
              "extend"}.has(tokens[start_pos].str)
             or (is_moose64 and {"struct"}.has(
                tokens[start_pos].str))) and
            start_pos + 1 <= tokens.len and
            tokens[start_pos + 1].kind == T_IDENT {
        return yes
    }
    return no
}

## @func surely_starts_stmt_even_in_bad_code
## Check whether a given token at the given position looks like
## it absolutely is intended to start a new statement, even in code
## that is assumed to be super broken. This function tries to model
## user intent, and only returns @{yes} on a subset of super clear
## situations when the grammar would otherwise mandate a new statement
## starting in more cases than recognized here.
##
## @param tokens ([Token], [str]) List of tokens to check a new
##   statement start in.
## @param start_pos num Token position to check for a new statement
##   starting.
## @param break_out_of_code_blocks bool Whether to return @{yes} on
##   statement starts that if found inside nested code block
##   `{...}` brackets, would not end the code block.
## @returns bool Returns @{yes} if this function is extremely certain
##   that a new statement was intended to start at the given position.
func surely_starts_stmt_even_in_bad_code(
        tokens, start_pos, break_out_of_code_blocks=yes
        ) {
    if start_pos > tokens.len or start_pos < 1 {
        return yes
    }
    if (tokens[start_pos].kind == T_KEYWORD and
            {"type", "import", "enum", "extend"}.has(
                tokens[start_pos].str) and
            (tokens[start_pos].str == "extend" or
             start_pos <= 1 or
             tokens[start_pos - 1].str != "extend") and
            start_pos + 1 <= tokens.len and
            tokens[start_pos + 1].kind == T_IDENT) {
        return yes
    }
    if break_out_of_code_blocks {
        if tokens[start_pos].kind == T_KEYWORD and
                {"var", "const"}.has(
                    tokens[start_pos].str
                ) and
                start_pos + 1 <= tokens.len and
                tokens[start_pos + 1].kind == T_IDENT {
            return yes
        }
        if tokens[start_pos].kind == T_KEYWORD and
                {"while", "await", "for", "with", "do",
                "return"}.has(
                    tokens[start_pos].str
                ) {
            return yes
        }
        if tokens[start_pos].kind == T_IDENT and
                start_pos + 1 <= tokens.len and
                tokens[start_pos + 1].kind == T_MATHASSIGN {
            return yes
        }
    }
    return no
}

## Turn a list of strings, like `["func", "main", "{", "}"]`,
## into the associated list of @{tokens|Token}. Throws a
## @{ValueError} if any string entry doesn't correspond to a
## singular known token.
## @param internal_labels bool Whether to allow internal identifier
##   labels starting with a `$` character or not. (Default: no.)
## @returns [@Token] Resulting list of tokens
func token_list_from_str_list(strlist, internal_labels=no) {
    var resultlist = []
    var token_no = 0
    for str in strlist {
        token_no += 1
        var result = tokenize_str(
            str, keep_whitespace=no,
            keep_comments=no,
            auto_recovery=no,
            internal_labels=internal_labels,
            _assume_previous_token=
                if token_no > 1 (resultlist.last()) else (none)
        )
        if result.tokens.len != 1 {
            throw new ValueError("Str item " +
                "doesn't translate to singular token.")
        }
        resultlist.add(result.tokens[1])
    }
    return resultlist
}

## @func get_naive_stmt_or_expr_len
## Get the length of the statement starting at the given token position.
## Can also be used mid-statement if you give the current bracket nesting
## depth inside the statement.
## Since this doesn't rely on the proper AST parser, it may return
## a length that is too short (but never one that is too long).
##
## @param tokens ([Token], [str]) The list of tokens supplied either as
##   @{Token} instances or @{str}s.
## @param start_pos num From where to advance forward to compute the
##   remaining statement length (or, strictly speaking, a lower boundary).
## @param bracket_depth num The bracket nesting depth inside the statement
##   if `start_pos` isn't the very start of the statement to find the
##   ending of.
## @param max_len num If specified, the maximum length returned is the
##   specified value here.
## @returns num The remaining length of the next statement from the given
##   `start_pos`.
func get_naive_stmt_or_expr_len(
        tokens, start_pos, bracket_depth=0, max_len=none,
        for_expr=no, is_moose64=no
        ) {
    if bracket_depth < 0 {
        throw new ValueError("Initial bracket_depth must "
            "be a non-negative number.")
    }
    var tokens_len = tokens.len
    if max_len != none {
        tokens_len = math.min(tokens_len, max_len)
    }

    if start_pos > tokens_len or (for_expr and
            bracket_depth == 0 and
            (tokens[start_pos].kind == T_ENCLOSE and
             {")", "]", "}"}.has(tokens[start_pos]))) {
        return 1
    }
    var possible_code_block_brackets = bracket_depth
    var i = start_pos
    while i <= tokens_len and (
            bracket_depth > 0 or
            i == start_pos or
            not can_stmt_or_expr_end_before_token(
            tokens, i, for_expr=for_expr, is_moose64=is_moose64
            )) {
        if tokens[i].kind == T_COMMA and
                bracket_depth == 0 and for_expr {
            break
        }
        if tokens[i].kind == T_ENCLOSE {
            if {"(", "{", "["}.has(tokens[i].str) {
                bracket_depth += 1
                if tokens[i].str == "{" {
                    possible_code_block_brackets += 1
                }
            } elseif {")", "}", "]"}.has(tokens[i].str) {
                bracket_depth -= 1
                if tokens[i].str == "}" {
                    possible_code_block_brackets =
                        math.max(possible_code_block_brackets - 1, 0)
                }
                if bracket_depth < 0 and i > start_pos {
                    break
                }
            }
        } else {
            if i > start_pos and
                    surely_starts_stmt_even_in_bad_code(
                        tokens, i, break_out_of_code_blocks=
                            (possible_code_block_brackets == 0)
                    ) {
                break
            }
        }
        i += 1
    }
    return (i - start_pos)
}

## @func get_inline_if_conditional_end
## Check whether the given 'if' keyword token is an inline
## one or a statement, and then return the token index
## just *past* the conditional.
## @returns num Returns the index of the first token
##   no longer part of the conditional for an inline if,
##   otherwise -1.
func get_inline_if_conditional_end(
        tokens, pos, max_len=none, is_moose64=no
        ) {
    var token_len = tokens.len
    const startpos = pos
    if max_len != none and max_len < token_len {
        token_len = max_len
    }
    if tokens[pos].kind != T_KEYWORD or
            tokens[pos].str != "if" {
        return -1
    }
    pos += 1
    var inline_if_depth = 1
    var bracket_depth = 0
    while pos <= token_len {
        if bracket_depth == 0 {
            if tokens[pos].kind == T_ENCLOSE and
                    tokens[pos].str == "{" and
                    not token_has_righthand(tokens[pos - 1]) {
                return -1
            }
            if tokens[pos].kind == T_KEYWORD {
                if tokens[pos].str == "if" {
                    inline_if_depth += 1
                } elseif tokens[pos].str == "else" {
                    if inline_if_depth > 1 {
                        inline_if_depth = math.max(
                            1, inline_if_depth - 1
                        )
                        pos += 1
                        continue
                    }
                    if (tokens[pos - 1].kind != T_ENCLOSE or
                            tokens[pos - 1].str != ")") {
                        return -1
                    }
                    # Find out where the first branch value started:
                    pos -= 2
                    var inner_bracket_depth = 1
                    while pos >= startpos + 2 {
                        if tokens[pos].kind == T_ENCLOSE {
                            if {")", "]", "}"}.has(tokens[pos].str) {
                                inner_bracket_depth += 1
                            } else {
                                assert({"(", "[", "{"}.has(
                                    tokens[pos].str))
                                inner_bracket_depth -= 1
                                if inner_bracket_depth <= 0 {
                                    if tokens[pos].str != "(" {
                                        return -1
                                    }
                                    return pos
                                }
                            }
                        }
                        pos -= 1
                    }
                    return -1
                } elseif is_maybe_token_str(
                        tokens[pos].str, is_moose64=is_moose64) and
                        not {"func", "if"}.has(tokens[pos].str) {
                    return -1
                }
            }
        }
        if tokens[pos].kind == T_ENCLOSE {
            if {"(", "[", "{"}.has(tokens[pos].str) {
                bracket_depth += 1
            } else {
                assert({")", "]", "}"}.has(tokens[pos].str))
                bracket_depth = math.max(0, bracket_depth - 1)
            }
            pos += 1
            continue
        }
        pos += 1
    }
    return -1
}

## @func token_is_consumed_by_return_simple
## Checks if this type of token, if following a 'return' keyword,
## simplified pre-check. Use @{check_tokens_consumed_by_return}
## for reliable result and to avoid false-positive yes results.
##
## @param t (Token or str) The token to be pondered as a 'return'
##   argument
## @returns bool @{yes|Yes} if it's a return argument, @{no} if not
func token_is_consumed_by_return_simple(t, is_moose64=no) {
    if typename(t) == "str" {
        var result = tokenize_str(
            t, keep_whitespace=no,
            keep_comments=no,
            auto_recovery=no,
            internal_labels=no,
        )
        if result.tokens.len != 1 {
            throw new ValueError("Not a single token.")
        }
        t = result.tokens[1]
    }
    if t.kind == T_ENCLOSE {
        return {"{", "(", "["}.has(t.str)
    }
    if t.kind == T_KEYWORD and
            is_maybe_token_str(t.str, is_moose64=is_moose64) and
            t.str != "func" and t.str != "if" {
        return no
    }
    return yes
}

## @func check_tokens_consumed_by_return
## Checks if this type of token, if following a 'return' keyword,
## will be considered a follow-up argument to be returned (rather
## than a separate follow-up statement).
##
## @param tokens list The list of tokens in which to check.
## @param pos num The token index where the maybe-consumed
##     expression starts.
## @param max_len The maximum length for the tokens list
##     that is considered as reachable, checkable range.
## @returns bool @{yes|Yes} if it's a return argument, @{no} if not
func check_tokens_consumed_by_return(
        tokens, pos, max_len=none, is_moose64=no
        ) {
    if max_len == none or max_len > tokens.len {
        max_len = tokens.len
    }
    const tokens_len = max_len
    if pos > tokens_len {
        return no
    }
    if not token_is_consumed_by_return_simple(
            tokens[pos], is_moose64=is_moose64
            ) {
        return no
    }
    if tokens[pos].kind == T_IDENT {
        var idx = call_or_assign_stmt.check_call_or_assign_and_get_idx(
            tokens, tokens_len, pos, only_assigns=yes
        )
        if idx >= 0 {
            return no
        }
    }
    return yes
}

## @func can_stmt_or_expr_end_before_token
## Check if a statement starts somewhere earlier in the given
## `tokens` token list, this statement possibly ends before the
## token found at `tok_pos` given there is no bracket left open.
## The `tok_pos` may be past the ending of the list, in which case
## the result is always @{yes}.
##
## @returns bool @{yes} If statement ends before specified token,
##   @{no} if it continues further and includes the specified token.
func can_stmt_or_expr_end_before_token(
        tokens, tok_pos, for_expr=no, is_moose64=no
        ) {
    if tok_pos > tokens.len {
        return yes
    }
    if tok_pos <= 1 {
        return no
    }
    assert(tokens[tok_pos - 1].str != "+" or
           token_has_righthand(tokens[tok_pos - 1]))
    if token_has_righthand(tokens[tok_pos - 1]) or
            ast_typeref.is_pos_inside_func_return_type(
                tokens, tok_pos, is_moose64=is_moose64) or
            func_stmt.is_pos_inside_possible_func_prop_list(
                tokens, tok_pos, is_moose64=is_moose64) {
        return no
    }
    if token_has_lefthand(tokens[tok_pos]) {
        return no
    }
    if tokens[tok_pos - 1].kind == T_KEYWORD and
            tokens[tok_pos - 1].str == "readonly" {
        var is_func_property = no
        var bdepth = 0
        var pos = tok_pos - 1
        while pos - 1 >= 1 {
            pos -= 1
            if tokens[pos].kind == T_ENCLOSE {
                if {")", "]", "}"}.has(tokens[pos]) {
                    bdepth += 1
                    continue
                } elseif {"(", "[", "{"}.has(tokens[pos]) {
                    bdepth -= 1
                    continue
                }
            } elseif bdepth <= 0 and
                    tokens[pos].kind == T_RIGHTPTR {
                is_func_property = yes
                break
            } elseif bdepth <= 0 and
                    tokens[pos].kind == T_LEFTPTR {
                is_func_property = no
                break
            } elseif bdepth <= 0 and
                    (tokens[pos].kind == T_ASSIGN or
                     tokens[pos].kind == T_MATHASSIGN) {
                is_func_property = no
                break
            } elseif tokens[pos].kind == T_KEYWORD and
                    bdepth <= 0 and
                    tokens[pos].str == "func" {
                is_func_property = yes
                break
            } elseif tokens[pos].kind == T_KEYWORD and
                    bdepth <= 0 and
                    (_maybe_stmt_token_strs.has(
                        tokens[pos].str
                    ) or (is_moose64 and
                    _maybe_stmt_token_strs_moose64.has(
                        tokens[pos].str
                    ))) {
                is_func_property = no
                break
            }
        }
        if is_func_property {
            return no
        }
    }
    if tokens[tok_pos - 1].kind == T_KEYWORD and
            tokens[tok_pos - 1].str == "failed" {
        if tok_pos > 2 and
                tokens[tok_pos - 2].kind == T_KEYWORD and
                tokens[tok_pos - 2].str == "return" and
                not check_tokens_consumed_by_return(
                    tokens, tok_pos, is_moose64=is_moose64
                ) {
            return yes
        }
        return no
    }
    if tokens[tok_pos - 1].kind == T_STR and
            tokens[tok_pos].kind == T_STR {
        return no
    }
    if tokens[tok_pos - 1].kind == T_BYTES and
            tokens[tok_pos].kind == T_BYTES {
        return no
    }
    if tokens[tok_pos - 1].kind == T_KEYWORD and
            {"return", "throw"}.has(tokens[tok_pos - 1]) {
        if check_tokens_consumed_by_return(
                tokens, tok_pos, is_moose64=is_moose64
                ) {
            return no
        }
        return yes
    }
    if tokens[tok_pos - 1].kind == T_KEYWORD and
            tokens[tok_pos - 1].str == "later" {
        if (tokens[tok_pos].kind == T_KEYWORD and
                {"ignore", "repeat"}.has(
                    tokens[tok_pos].str
                )) or
                tokens[tok_pos].kind == T_COLON {
            return no
        } elseif tok_pos >= 3 and
                tokens[tok_pos - 2].kind == T_KEYWORD and
                tokens[tok_pos - 2].str == "return" and
                check_tokens_consumed_by_return(
                    tokens, tok_pos, is_moose64=is_moose64
                ) {
            return no
        }
        return yes
    }
    if not for_expr and
            tokens[tok_pos].kind == T_NEWOP {
        return no
    }
    return yes
}

## @func skip_garbage_to_closing_item
## Skip past invalid malformed inner nested expression that
## is supposedly terminated by something, to find that terminating
## item. Will bail out early if we clearly ran into a follow-up
## statement instead.
## @params tokens [Tokens] The tokens stream to skip forward in
##   to the closing position.
## @params pos num The starting position to skip forward from.
## @params closing_kind TokenKind The token kind of the expected
##   closing or ending @{token|Token}.
## @params closing_str str The `.str` attribute of the expected
##   closing or ending @{token|Token}.
## @params max_len (none, num) The maximum length of the tokens
##   stream we are allowed to forward in, or @{none} if unrestricted.
## @params skip_closing_item_itself bool If set to @{yes}, skips
##   to the position *past* the closing item at the end if found.
##   Defaults to @{none}, returning the closing item itself instead.
## @returns num The new position in the token stream after skipping
##   to the closing item.
func skip_garbage_to_closing_item(
        tokens, pos, closing_kind, closing_str, max_len=none,
        skip_closing_item_itself=yes,
        ) {
    var tokens_len = tokens.len
    if max_len != none {
        tokens_len = math.min(tokens_len, max_len)
    }

    # Try to find actual closing bracket:
    var possible_code_brackets = 0
    var bdepth = 0
    while pos <= tokens_len and
            (bdepth > 0 or
             ((tokens[pos].kind != T_ENCLOSE or
               not {")", "]", "}"}.has(tokens[pos].str)) and
              (tokens[pos].kind != closing_kind or
               tokens[pos].str != closing_str))) {
        # Track inner nestings:
        if tokens[pos].kind == T_ENCLOSE {
            if {"(", "[", "{"}.has(tokens[pos].str) {
                bdepth += 1
                if tokens[pos].str == "{" {
                    possible_code_brackets += 1
                }
            } else {
                bdepth = math.max(0, bdepth - 1)
                if tokens[pos].str == "}" {
                    possible_code_brackets = math.max(
                        0, possible_code_brackets - 1
                    )
                }
            }
        }
        # If we run into obviously the next statement,
        # bail out early:
        if bdepth == 0 and
                surely_starts_stmt_even_in_bad_code(
                tokens, pos, break_out_of_code_blocks=
                (possible_code_brackets == 0)) {
            break
        }
        pos += 1
    }
    if skip_closing_item_itself {
        if pos <= tokens_len {
            pos += 1
        }
    }
    return pos
}

## If the given position is pointing to the opening
## bracket token for a code block, try to skip over the
## code block. (If the code block is broken, this might fail.)
## The maximum index this can skip to is `tokens.len + 1`
## or `max_len + 1` if a maximum length is supplied, whichever
## is smaller.
func skip_code_block_if_any(
        tokens, startpos, max_len=none, is_moose64=no
        ) {
    var token_len = tokens.len
    if max_len != none and max_len < token_len {
        token_len = max_len
    }
    var pos = startpos

    if pos < 1 or pos > token_len or
            tokens[pos].kind != T_ENCLOSE or
            tokens[pos].str != "{" {
        return 0
    }
    pos += 1  # Past '{' bracket.

    var block_depth = 1
    while pos <= token_len {
        if pos <= token_len and block_depth <= 1 and
                tokens[pos].kind == T_ENCLOSE and
                tokens[pos].str == "}" {
            return (pos - startpos) + 1
        }
        if tokens[pos].kind == T_ENCLOSE {
            if tokens[pos].str == "{" {
                block_depth += 1
                pos += 1
                continue
            } elseif tokens[pos].str == "}" {
                block_depth = math.max(block_depth - 1, 0)
                pos += 1
                continue
            }
        }
        var skiplen = get_naive_stmt_or_expr_len(
            tokens, pos, bracket_depth=math.max(block_depth - 1, 0),
            is_moose64=is_moose64
        )
        pos += skiplen
        if pos > token_len {
            return (token_len - startpos) + 1
        }
    }
    return (pos - startpos) + 1
}

## In a broken statement of some kind that has code blocks,
## try to skip the broken stuff until we reach a code block
## or until the most likely ending point if it's incomplete.
func skip_in_broken_stmt_to_code_block(
        tokens, startpos, bracket_depth=0, max_len=none,
        is_moose64=no
        ) {
    var token_len = tokens.len
    if max_len != none and max_len < token_len {
        token_len = max_len
    }
    var pos = startpos
    while yes {
        var skiplen = get_naive_stmt_or_expr_len(
            tokens, pos, bracket_depth=bracket_depth,
            is_moose64=is_moose64
        )
        var skipto = pos + math.max(1, skiplen) - 1
        while pos <= skipto {
            if pos > token_len or (
                    bracket_depth <= 0 and
                    tokens[pos].kind == T_ENCLOSE and
                    tokens[pos].str == "{" and
                    (pos <= 1 or not token_has_righthand(
                        tokens[pos - 1]
                    ))) {
                return pos - startpos
            }
            if bracket_depth == 0 and
                    surely_starts_stmt_even_in_bad_code(
                        tokens, pos
                    ) {
                return pos - startpos
            }
            if tokens[pos].kind == T_ENCLOSE {
                if {"{", "(", "["}.has(tokens[pos].str) {
                    bracket_depth += 1
                } else {
                    assert({"}", ")", "]"}.has(tokens[pos].str))
                    bracket_depth = math.max(bracket_depth - 1, 0)
                }
            }
            pos += 1
        }
    }
}

## Check if the given token is a syntatic element like a binary
## operator that necessarily requires a follow-up right-hand side.
func token_has_righthand(t) {
    if {T_MATH, T_UNARYMATH,
            T_BOOLCOMP, T_COMPARE,
            T_ASSIGN, T_MATHASSIGN,
            T_LEFTPTR,
            T_RIGHTPTR, T_COMMA,
            T_DOT}.has(t.kind) {
        return yes
    }
    if (t.kind == T_KEYWORD and {"func", "import",
            "type", "later", "extend", "in",
            "as", "from", "with", "for", "if",
            "elseif", "else", "do", "rescue",
            "finally", "await", "failable",
            "override",
            "var", "const", "throw",
            "enum"}.has(t.str)) or
            t.kind == T_NEWOP {
        return yes
    }
    return no
}

## Check if the given token is a syntatic element like a binary
## operator that necessarily requires a leading left-hand side.
func token_has_lefthand(t) {
    if {T_MATH, T_COMPARE,
            T_ASSIGN, T_MATHASSIGN,
            T_LEFTPTR, T_RIGHTPTR, T_COMMA,
            T_DOT}.has(t.kind) {
        return yes
    }
    if t.kind == T_ENCLOSE and
            {"[", "("}.has(t.str) {
        return yes
    }
    if t.kind == T_BOOLCOMP and t.str != "not" {
        return yes
    }
    if t.kind == T_KEYWORD and {
            "as", "from", "in", "failable",
            "override", "readonly",
            "elseif", "else", "rescue",
            "finally", "later",
            "protect"}.has(t.str) {
        return yes
    }
    return no
}

## Check if the given @{str} or @{token|Token} is a label
## representing a Horse64 special keyword or not.
## @returns bool @{Yes|yes} if keyword, otherwise @{no}.
func is_special_word(value, is_moose64=no) {
    if has_attr(value, "str") {
        return value.kind == T_KEYWORD or
            value.kind == T_BOOL or
            value.kind == T_NONE or
            value.kind == T_BOOLCOMP
    }
    if is_moose64 and special_words_moose64_only.has(value) {
        return yes
    }
    return special_words.has(value)
}

## Check if the given @{str} or @{token|Token} is
## valid in Horse64 for representing a user-defined
## identifier or a built-in keyword.
## @returns bool @{Yes|yes} if valid as identifier or
##   keyword, otherwise @{no}.
func is_identifier_or_keyword(value, internal_labels=no) {
    if has_attr(value, "str") {
        return (value.kind == T_IDENT)
    }
    if value.len == 0 {
        return no
    }
    const code_a = text.code("a")
    const code_z = text.code("z")
    const code_cap_a = text.code("A")
    const code_cap_z = text.code("Z")
    const code_0 = text.code("0")
    const code_9 = text.code("9")
    var c = value[1]
    if c == "_" or text.code(c) > 127 or
            (text.code(c) >= code_a and
            text.code(c) <= code_z) or
            (text.code(c) >= code_cap_a and
            text.code(c) <= code_cap_z) or
            (internal_labels and c == "$") {
        # That's an identifier or keyword.
        var hadnondollar = (c != '$')
        var i = 2
        while i <= value.len {
            c = value[i]
            if (c == "_" or text.code(c) > 127 or
                    (text.code(c) >= code_a and
                    text.code(c) <= code_z) or
                    (text.code(c) >= code_cap_a and
                    text.code(c) <= code_cap_z) or
                    (text.code(c) >= code_0 and
                    text.code(c) <= code_9) or
                    (internal_labels and c == "$")) {
                if c != "$" {
                    hadnondollar = yes
                }
                i += 1
                continue
            }
            return hadnondollar
        }
        return yes
    }
    return no
}

## Reverse all the bracket types known in Horse64 source
## code in the given string to the opposite. E.g. an input
## of `"(]"` will return `")["`. Used by the tokenizer.
func reverse_brackets(value) {
    if typename(value) == "list" and (
            value.len == 0 or
            typename(value[1]) == "str") {
        var result = []
        for bracket in value {
            result.add(reverse_brackets(bracket))
        }
        return result
    }
    if typename(value) != "str" {
        throw new TypeError("value must be bytes or str.")
    }
    var valuenew = ""
    var i = 1
    while i <= value.len {
        if value[i] == "(" {
            valuenew += ")"
        } elseif value[i] == "[" {
            valuenew += "]"
        } elseif value[i] == "{" {
            valuenew += "}"
        } elseif value[i] == ")" {
            valuenew += "("
        } elseif value[i] == "]" {
            valuenew += "["
        } elseif value[i] == "}" {
            valuenew += "{"
        } else {
            valuenew += value[i]
        }
        i += 1
    }
    return valuenew
}

## Possible values for @{Token.kind}.
enum TokenKind {
    T_COMMENT,
    T_WSPACE,
    T_ENCLOSE,
    T_STR,
    T_CHARCODE,
    T_INLINECODE,
    T_BYTES,
    T_NUM,
    T_BIGNUM,
    T_KEYWORD,
    T_BOOL,
    T_IDENT,
    T_NONE,
    T_MATH,
    T_NEWOP,
    T_UNARYMATH,
    T_BOOLCOMP,
    T_COMPARE,
    T_ASSIGN,
    T_MATHASSIGN,
    T_LEFTPTR,
    T_RIGHTPTR,
    T_COMMA,
    T_DOT,
    T_COLON,
    T_ELLIPSIS,
}

type Token {
    ## @type num
    var line

    ## @type num
    var col

    ## @type str
    var str

    ## @type TokenKind
    var kind
}

func Token.as_str {
    var t = "Token("
    t += "str=" + describe_token_str(self.str)
    t += ",kind=" + TokenKind.num_label(self.kind)
    if self.line != none {
        t += ",line=" + self.line.as_str()
        if self.col != none {
            t += ",col=" + self.col.as_str()
        }
    }
    return t + ")"
}

func Token.init(str, kind, line, col) {
    self.kind = kind
    self.str = str
    self.line = line
    self.col = col
}

type TokensResult {
    ## @type [msg.FileMsg]
    var msgs = []

    ## @type [Token]
    var tokens = []

    ## @types (project.ProjectFile, none)
    var project_file
}

func TokensResult.as_json_obj {
    var output = {
        "messages"-> [],
        "tokens"-> [],
    }
    for m in self.msgs {
        var mjson = {
            "message"-> m.message,
            "kind"-> msg.MsgKind.num_label(m.kind),
            "line"-> m.line,
            "col"-> m.col,
            "file"-> none,
        }
        if m.source_file != none {
            mjson["file"] = m.source_file.source_uri
        }
        output["messages"].add(mjson)
    }
    for t in self.tokens {
        output["tokens"].add({
            "str"-> t.str,
            "kind"-> TokenKind.num_label(t.kind),
            "line"-> t.line,
            "col"-> t.col,
        })
    }
    return output
}

func TokensResult.as_str {
    var t = "TokensResult(tokens=["
    var max_print_tokens = 10
    var i = 1
    while i <= self.tokens.len and i <= max_print_tokens {
        if i > 1 {
            t += ","
        }
        t += self.tokens[i].as_str()
        i += 1
    }
    if self.tokens.len > max_print_tokens {
        t += ",..."
    }
    t += "]),msgs=#" + self.msgs.len.as_str()
    return t + ")"
}

func describe_token_at(tokens, i) {
    if i > tokens.len {
        return "end of code"
    } elseif i < 1 {
        return "start of code"
    } else {
        return describe_token(tokens[i])
    }
}

func describe_token(t) {
    if t.kind == T_LEFTPTR {
        return "'<-' (T_LEFTPTR)"
    } elseif t.kind == T_RIGHTPTR {
        return "'->' (T_RIGHTPTR)"
    }
    return describe_token_str(t.str) + " (" +
        TokenKind.num_label(t.kind) + ")"
}

func describe_token_str(s) {
    if alike_num(s) {
        return s
    }
    if s == "..." {
        return "'...'"
    }
    if s.glyph_len <= 1 {
        return describe_char_at(s, 1, maybe_cutoff_glyph=no)
    }
    if {"<-", "->"}.has(s) {
        return "'" + s.as_str() + "'"
    }
    if s.startswith("'") or s.startswith('"') or
            s.startswith("b'") or s.startswith('b"') {
        var result = ""
        var quote = s[1]
        if quote == "b" {
            quote = s[2]
        }
        var maxlen = 32
        var pos = 1
        while pos <= s.len {
            if pos > maxlen {
                result += "..." + quote
                break
            }
            if s[pos] == '\\' {
                # Fix some of the "extra wrong" escape fumbles:
                if pos + 1 > s.len or
                        text.code(s[pos + 1]) < 32 {
                    result += "\\"
                }
                result += "\\"
                pos += 1
                continue
            }
            if s[pos] == '\t' {
                result += "\\t"
                pos += 1
                continue
            }
            if s[pos] == '\0' {
                result += "\\0"
                pos += 1
                continue
            }
            if s[pos] == '\n' {
                result += "\\n"
                pos += 1
                continue
            }
            if s[pos] == '\r' {
                result += "\\r"
                pos += 1
                continue
            }
            result += s[pos]
            pos += 1
        }
        return result
    }
    if is_identifier_or_keyword(s) or math_assign_ops.has(s) or
            math_ops.has(s) or s == "=" or compare_ops.has(s) {
        return "'" + s + "'"
    }
    return "<unprintable token>"
}

func describe_char_at(
        s, i, maybe_cutoff_glyph=no
        ) {
    if s == "" or i > s.len or i < 1 {
        return "''"
    }

    var c = s.sub(i, i)
    var codepoint = text.code(c)
    if codepoint >= 32 and codepoint <= 126 {
        # Nice ASCII range, just print it:
        if c == "'" {
            return '"\'"'
        }
        return "'" + c + "'"
    }
    if codepoint < 32 {
        # This is a range we definitely want to escape:
        var result = "'\\x"
        hexstr = text.code(c).as_hex()
        if hexstr.len < 2 {
            result += "0"
        }
        return result + hexstr + "'"
    }
    if codepoint == 127 {
        return "'\\x7F'"
    }

    # If we arrive here it's a multibyte char.

    # See if this is a complete glyph:
    var glyph_indexes = text.glyph_codepoint_len(s, pos=i)
    if glyph_indexes <= s.len - i or not maybe_cutoff_glyph {
        # We guaranteed got the full glyph.
        return "'" + s.sub(i, i + 10).glyph_sub(1, 1) + "'"
    }

    # We can't know if we have the full glyph. Better escape:
    var hexstr = text.code(c).as_hex()
    while hexstr.len < 8 {
        hexstr = "0" + hexstr
    }
    return "'\\u" + hexstr + "'"
}

## Escape a string such that it could be written out into a Horse64
## code file again as a single token, by escaping back slashes etc.
func as_escaped_code_string(
        s, quote_type='"', never_escape_quotes=no
        ) {
    return textfmt.as_escaped_code_string(
        s, quote_type=quote_type,
        never_escape_quotes=never_escape_quotes
    )
}

## Figure out if any instance of <- is a T_LEFTPTR as used
## for type annotations, or instead < - as used for "less
## than" operator followed by a math negative sign.
## @returns bool @{yes} if this is possibly T_LEFTPTR, @{no} if not.
func is_leftptr_at_token_str_pos(
        token_str, token_pos, past_tokens,
        is_isolated_type=no, is_moose64=no,
        debug=no
        ) {
    var program_name = if is_moose64 ("moosec") else ("horsec")
    if debug {
        print(program_name + ": debug: " +
            "is_leftptr_at_token_str_pos(): "
            "Called to check potential <- at "
            "token_pos=" + token_pos.as_str() + " "
            "with is_isolated_type=" +
                is_isolated_type.as_str() + " "
            "past_tokens.len=" + past_tokens.len.as_str())
    }
    if token_pos <= 1 or {"-", ">", "<",
            ")", "}", "]", "{", "[", "="}.has(
                token_str[token_pos - 1]
            ) {
        return no
    }
    var bracket_depth = 0
    var k = past_tokens.len
    while k >= 1 {
        if debug {
            print(program_name + ": debug: " +
                "is_leftptr_at_token_str_pos(): "
                "Looking at past_tokens[" +
                    k.as_str() + "]=" +
                past_tokens[k].as_str())
        }
        var kind = past_tokens[k].kind
        if {T_MATH, T_UNARYMATH, T_BOOL, T_NUM,
                T_ASSIGN, T_MATHASSIGN
                }.has(kind) {
            return no
        }
        if kind == T_ENCLOSE and
                {")", "]", "}"}.has(past_tokens[k].str) {
            bracket_depth += 1
            if bracket_depth >= 1 {
                # Skip over inner bracket nestings.
                var inner_bdepth = 1
                var z = k - 1
                while z >= 1 {
                    if past_tokens[z].kind == T_ENCLOSE and
                            {"(", "[", "{"}.has(
                                past_tokens[z].str) {
                        inner_bdepth -= 1
                        if inner_bdepth <= 0 {
                            break
                        }
                    } elseif past_tokens[z].kind == T_ENCLOSE and
                            {")", "]", "}"}.has(
                                past_tokens[z].str) {
                        inner_bdepth += 1
                    }
                    z -= 1
                }
                k = z - 1
            } else {
                k -= 1
            }
            continue
        }
        if kind == T_ENCLOSE and
                is_isolated_type and past_tokens[k].str == "(" {
            if k <= 1 or past_tokens[k - 1].kind == T_RIGHTPTR or
                    past_tokens[k - 1].kind == T_LEFTPTR {
                # This is part of a (... <- test) -> ... func type.
                return yes
            }
            bracket_depth -= 1
        }
        if kind == T_IDENT and k > 1 and
                past_tokens[k - 1].kind == T_KEYWORD and
                {"var", "const"}.has(past_tokens[k - 1].str) {
            return yes
        }
        if kind == T_KEYWORD and
                _maybe_stmt_token_strs.has(
                    past_tokens[k].str) and
                bracket_depth < 0 {
            return no
        }
        if {T_ELLIPSIS, T_IDENT}.has(kind) and k > 1 and
                (past_tokens[k - 1].kind == T_COMMA or
                 (past_tokens[k - 1].kind == T_ENCLOSE and
                  past_tokens[k - 1].str == "(")) {
            # Scan if we're part of a func definition:
            var bracket_depth = 0
            var z = k
            while z >= 1 {
                if past_tokens[z].kind == T_ENCLOSE and
                        {"(", "[", "{"}.has(past_tokens[z].str) {
                    bracket_depth -= 1
                } elseif past_tokens[z].kind == T_ENCLOSE and
                        {")", "]", "}"}.has(past_tokens[z].str) {
                    bracket_depth += 1
                }
                if bracket_depth == 0 and
                        past_tokens[z].kind == T_KEYWORD and
                        {"var", "const"}.has(past_tokens[z].str) {
                    return yes
                }
                if is_moose64 and bracket_depth < 0 and
                        past_tokens[z].kind == T_LEFTPTR {
                    # We must be part of a func typeref expr,
                    # specified as a type of a var.
                    return yes
                }
                if is_moose64 and bracket_depth < 0 and
                        past_tokens[z].kind == T_ENCLOSE and
                        z > 1 and past_tokens[z].str == '(' and
                        past_tokens[z - 1].kind == T_KEYWORD and
                        past_tokens[z - 1].str == "as" {
                    # We must be part of a type cast.
                    return yes
                }
                if bracket_depth <= 0 and
                        {T_MATH, T_UNARYMATH, T_BOOL, T_NUM,
                        T_ASSIGN, T_MATHASSIGN
                        }.has(past_tokens[z].kind) {
                    return no
                }
                if bracket_depth <= -1 and
                        past_tokens[z].kind == T_KEYWORD and
                        {"func"}.has(past_tokens[z].str) {
                    return yes
                }
                if bracket_depth <= 0 and
                        _maybe_stmt_token_strs.has(
                        past_tokens[z].str) {
                    return no
                }
                z -= 1
            }
            return no
        }
        k -= 1
    }
    return no
}

## Tokenize the given Horse64 code string to proper tokens.
## If auto recovery is enabled and the user forgets to close
## brackets or terminate strings, `tokenize_str` might try to
## repair the input and carry on anyway.
##
## @param str str The Horse64 code string to be tokenized.
## @param project_file project.ProjectFile The associated
##     code file for this code string, if any.
## @param auto_recovery bool Whether to try to auto repair after
##     errors to maybe still return a meaningful result. This may
##     improve error output but risks false positive later errors.
##     You should leave this enabled/set to @{yes} unless you
##     have a good reason not to, since it will improve error
##     message diagnostics as well.
## @param keep_whitespace bool Whether to keep whitespace tokens
##     (when set to @{yes})
##     or whether to discard them (set to @{no}, the default).
## @param keep_comments bool Whether to keep comment tokens
##     which happens when this option is set to @{yes},
##     or whether to discard them which happens with this
##     option set to @{no}. The default value is @{no}.
## @param internal_labels bool If set to @{yes}, identifiers may
##     start with a `$` which is invalid syntax except for
##     intermediate code transforms used internally. Defaults to
##     @{no}, don't change this unless you're certain.
## @param is_isolated_type bool If set to @{yes}, the parsed
##     tokens are assumed to be an isolated type rather than
##     a regular complete program or code line. This is needed
##     such that isolated func types are properly parsed,
##     since the tokenizer usually identifies those with the
##     help of the context of an entire code line. Therefore,
##     if you're parsing a singled-out type, set this to @{yes}.
##     Otherwise, leave it at the default value that is @{no}.
## @param _assume_previous_token (Token, none) For internal use
##     by @{token_list_from_str_list}. Can be set to a single
##     @{token|Token} to be assumed to be *before* the parsed
##     stream. Probably not something you'll need to use.
func tokenize_str(
        str, project_file=none,
        keep_whitespace=no,
        keep_comments=no,
        auto_recovery=yes,
        internal_labels=no,
        is_isolated_type=no,
        _assume_previous_token=none,
        is_moose64=no,
        debug=no,
        ) {
    var program_name = if is_moose64 ("moosec") else ("horsec")

    var result = new TokensResult()
    result.project_file = project_file
    var strlen = str.len

    var known_string_escapes = {
        "n", "r", "t", "x", "u", "0",
        "\\", '"', "'"
    }

    const code_a = text.code("a")
    const code_z = text.code("z")
    const code_cap_a = text.code("A")
    const code_cap_z = text.code("Z")
    const code_0 = text.code("0")
    const code_9 = text.code("9")
    var bracket_nesting = []
    var guessed_expr_bracket_nesting = []

    # Process the tokens:
    var line = 1
    var col = 0
    var i = 0
    var last_nonspace_token = _assume_previous_token
    while i < strlen {
        i += 1
        col += 1
        var c = str[i]
        if result.tokens.len > 0 and
                not {T_WSPACE, T_COMMENT}.has(
                    result.tokens.last().kind
                ) {
            last_nonspace_token = result.tokens.last()
        }

        if debug {
            print(program_name + ": debug: tokenize_str(): "
                "Looking at token #" + i.as_str() +
                ": " + describe_char_at(
                c, 1, maybe_cutoff_glyph=yes) +
                " || extra_info=" + [bracket_nesting,
                guessed_expr_bracket_nesting,
                is_isolated_type,
                result.msgs].as_str())
        }

        if i + 1 <= strlen and c == "-" and
                str[i + 1] == ">" {
            # -> map operator, or -> return type operator.
            result.tokens.add(new Token(
                "->", T_RIGHTPTR, line, col
            ))
            i += 1
            col += 1
            continue
        } elseif is_moose64 and i + 1 <= strlen and
                c == "<" and str[i + 1] == "-" and
                is_leftptr_at_token_str_pos(
                    str, i, result.tokens,
                    is_isolated_type=is_isolated_type,
                    is_moose64=is_moose64,
                    debug=debug
                ) {
            # <- type assign operator.
            result.tokens.add(new Token(
                "<-", T_LEFTPTR, line, col
            ))
            i += 1
            col += 1
            continue
        } elseif c == "." {
            if i + 2 <= strlen and
                    str[i + 1] == "." and
                    str[i + 2] == "." {
                result.tokens.add(new Token(
                    "...", T_ELLIPSIS, line, col
                ))
                i += 2  # Length 3, so skip additional 2.
                col += 2
                continue
            }
            # Dot.
            result.tokens.add(new Token(
                ".", T_DOT, line, col
            ))
            continue
        } elseif c == "," {
            # Comma.
            result.tokens.add(new Token(
                ",", T_COMMA, line, col
            ))
            continue
        } elseif c == ":" {
            # Colon.
            result.tokens.add(new Token(
                ":", T_COLON, line, col
            ))
            continue
        } elseif c == "'" or c == '"' or
                (c == "b" and i + 1 < strlen and
                 (str[i + 1] == "'" or str[i + 1] == '"')) or
                (c == "c" and
                 i + 1 < strlen and
                 (str[i + 1] == "'" or str[i + 1] == '"')) {
            # Str or bytes literal:
            var start_line = line
            var start_col = col
            var end_marker = c
            var is_bytes = no
            var is_char = no
            var literal_name = "string"
            var literal_prefix = ""
            var token_type = T_STR
            var k = i
            if c == "b" {
                literal_prefix = "b"
                is_bytes = yes
                end_marker = str[i + 1]
                literal_name = "bytes"
                token_type = T_BYTES
                k += 1
                col += 1
            } elseif c == "c" {
                literal_prefix = "c"
                is_char = yes
                end_marker = str[i + 1]
                literal_name = "char"
                token_type = T_CHARCODE
                k += 1
                col += 1
            }
            if k + 1 > strlen {
                result.msgs.add(new msg.FileMsg(
                    "Unterminated " +
                    literal_name + " "
                    "literal.",
                    source_file=project_file,
                    line=start_line, col=start_col
                ))
                result.tokens.add(new Token(
                    literal_prefix +
                    end_marker + end_marker,
                    token_type,
                    start_line, start_col))
                continue
            }

            # Find the end of the literal:
            var next_escaped = no
            var inner_start_idx = k + 1
            var inner_start_line = line
            var inner_start_col = col + 1
            while k + 1 <= strlen {
                k += 1
                col += 1
                if str[k] == "\r" {
                    col = 0
                    line += 1
                    next_escaped = no
                    if k + 1 < strlen and str[k + 1] == "\n" {
                        k += 1
                        continue
                    }
                } elseif str[k] == "\n" {
                    col = 0
                    line += 1
                    next_escaped = no
                    continue
                }
                if str[k] == "\\" {
                    if next_escaped {
                        next_escaped = no
                        continue
                    }
                    next_escaped = yes
                    if k + 1 > strlen or
                            not known_string_escapes.has(
                            str[k + 1]) {
                        result.msgs.add(new msg.FileMsg(
                            "Invalid string escape '\\' + " +
                            describe_char_at(str, k,
                                maybe_cutoff_glyph=no) + ".",
                            source_file=project_file,
                            line=line, col=col
                        ))
                    } elseif str[k + 1] == "x" and
                            parse_str_hex_escaping(
                                str, k
                            ) == none {
                        result.msgs.add(new msg.FileMsg(
                            "Invalid hex escape, needs to be "
                            "'\\' + 'x' + two hex digits, "
                            "e.g. \"\\x05\".",
                            source_file=project_file,
                            line=line, col=col
                        ))
                    }
                    continue
                } elseif str[k] == end_marker and
                        not next_escaped {
                    break
                }
                next_escaped = no
            }
            var cutoff = no
            if k > strlen or str[k] != end_marker {
                cutoff = yes
                result.msgs.add(new msg.FileMsg(
                    "Unterminated " +
                    literal_name + " "
                    "literal.",
                    source_file=project_file,
                    line=start_line, col=start_col
                ))
            }
            if cutoff and auto_recovery and
                    inner_start_idx <= strlen {
                # Try to guess where this literal should have been
                # terminated:
                var inner_string = str.sub(inner_start_idx)
                var inner_tokens_result = tokenize_str(
                    inner_string, keep_whitespace=no,
                    auto_recovery=no
                )
                var inner_tokens =
                    inner_tokens_result.tokens
                var recover_str_offset = none
                var j = 0
                while j < inner_tokens.len {
                    j += 1
                    var stroffset = none
                    if surely_starts_stmt_even_in_bad_code(
                            inner_tokens, j,
                            break_out_of_code_blocks=yes) {
                        # Might be a new statement. Terminate here.
                        recover_str_offset =
                            text.pos_from_line_col(
                                inner_string,
                                inner_tokens[j].line,
                                inner_tokens[j].col,
                                start_line=inner_start_line,
                                start_col=inner_start_col
                            )
                        if recover_str_offset != none {
                            break
                        }
                    }
                }
                if recover_str_offset != none {
                    # We got a recovery point. Try to repair:
                    var offset = recover_str_offset
                    var close_brackets_str =
                        guessed_expr_bracket_nesting.join("")
                    close_brackets_str =
                        reverse_brackets(
                        close_brackets_str)

                    # Insert the closing "/' and close all brackets
                    # (at least the brackets we're guessing)
                    str = str.sub(1, offset - 1) +
                        end_marker +
                        close_brackets_str +
                        str.sub(offset)

                    # Set ourselves to the new point and resume:
                    strlen = str.len
                    line = inner_tokens[j].line
                    col = inner_tokens[j].col - 1
                    col += close_brackets_str.len
                    for bracket in
                            guessed_expr_bracket_nesting {
                        if bracket_nesting.len > 0 {
                            bracket_nesting.pop()
                        }
                    }
                }
            }
            var strtok = new Token(
                str.sub(i, k),
                token_type,
                start_line, start_col
            )
            if token_type == T_CHARCODE {
                var val = parse_token_value(
                    strtok
                )
                if val.len != 1 {
                    result.msgs.add(new msg.FileMsg(
                        "Invalid T_CHARCODE " +
                        "literal of wrong length, "
                        "expected it to contain "
                        "text equivalent to a single "
                        "32bit widechar code point.",
                        source_file=project_file,
                        line=start_line, col=start_col
                    ))
                }
            }
            result.tokens.add(strtok)
            i = k
            continue
        } elseif c == "#" {
            # A line comment:
            var start_line = line
            var start_col = col
            col += 1
            var start_pos = i
            i += 1
            while i < strlen and str[i] != "\n" and
                    str[i] != "\r" {
                col += 1
                i += 1
            }
            col -= 1
            i -= 1
            if keep_comments {
                var comment = str.sub(start_pos, i)
                result.tokens.add(new Token(
                    comment, T_COMMENT, start_line, start_col
                ))
            }
            continue
        } elseif c == " " or c == "\t" or c == "\r" or c == "\n" {
            # Handle whitespace:
            var start_line = line
            var start_col = col
            var whitespace_start = i
            while i <= strlen and (
                    str[i] == " " or str[i] == "\t" or
                    str[i] == "\r" or str[i] == "\n") {
                if str[i] != "\r" and str[i] != "\n" {
                    col += 1
                    i += 1
                } else {
                    col = 1
                    line += 1
                    if str[i] == "\r" and i + 1 <= strlen and
                            str[i + 1] == "\n" {
                        i += 2
                    } else {
                        i += 1
                    }
                }
            }
            col -= 1
            i -= 1
            if keep_whitespace {
                var wspace = str.sub(whitespace_start, i)
                result.tokens.add(new Token(
                    wspace, T_WSPACE, start_line, start_col
                ))
            }
            continue
        } elseif c == "(" or c == "[" or c == "{" {
            # Opening brackets:
            if auto_recovery {
                guessed_expr_bracket_nesting.add(c)
            }
            bracket_nesting.add([c, line, col])
            result.tokens.add(new Token(
                c, T_ENCLOSE, line, col
            ))
            if result.tokens.len >= 3 and
                    result.tokens[result.tokens.len - 1].kind ==
                        T_STR and
                    result.tokens[result.tokens.len - 1].str.
                        lower() == "c" and
                    result.tokens[result.tokens.len - 2].kind ==
                        T_KEYWORD and
                    result.tokens[result.tokens.len - 2].str == "do" {
                # This means that an inline C block follows.
                # We need to find out where it ends.
                var bracket_depth = 0
                var inside_quotes = none
                var startcol = col + 1
                var startline = line
                var starti = i + 1
                while i + 1 <= strlen {
                    i += 1
                    col += 1
                    if str[i] == "\r" {
                        col = 0
                        line += 1
                        if i + 1 <= strlen and
                                str[i + 1] == "\n" {
                            i += 1
                            continue
                        }
                        continue
                    } elseif str[i] == "\n" {
                        col = 0
                        line += 1
                        continue
                    }
                    if inside_quotes == none and
                            (str[i] == "'" or
                            str[i] == '"') {
                        inside_quotes = str[i]
                        continue
                    } elseif inside_quotes == str[i] {
                        inside_quotes = none
                        continue
                    } elseif inside_quotes == none and
                            {"{", "[", "("}.has(str[i]) {
                        bracket_depth += 1
                        continue
                    } elseif inside_quotes == none and
                            {"}", "]", ")"}.has(str[i]) {
                        bracket_depth -= 1
                        if bracket_depth < 0 {
                            break
                        }
                        continue
                    } elseif inside_quotes == none and
                            str[i] == "\\" {
                        i += 1
                        col += 1
                        continue
                    }
                }
                if line > startline or col > startcol {
                    result.tokens.add(new Token(
                        str.sub(
                            starti, i
                        ), T_INLINECODE, startline, startcol
                    ))
                }
                continue
            }
            continue
        } elseif c == ")" or c == "]" or c == "}" {
            # Closing brackets:
            if auto_recovery and
                    guessed_expr_bracket_nesting.len > 0 {
                guessed_expr_bracket_nesting.pop()
            }
            if bracket_nesting.len == 0 {
                result.msgs.add(new msg.FileMsg(
                    "Invalid unexpected closing bracket '" +
                    c + "', no brackets left open",
                    source_file=project_file,
                    line=line, col=col
                ))
            } else {
                var reversec = reverse_brackets(c)
                assert(reversec != c)
                var openinfo = bracket_nesting.last()
                if openinfo[1] != reversec {
                    result.msgs.add(new msg.FileMsg(
                        "Invalid unexpected closing bracket '" +
                        c + "', expected match for '" +
                        openinfo[1] + "' in line " +
                        openinfo[2].as_str() + ", column " +
                        openinfo[3].as_str(),
                        source_file=project_file,
                        line=line, col=col
                    ))
                }
                bracket_nesting.pop()
            }
            result.tokens.add(new Token(
                c, T_ENCLOSE, line, col
            ))
            continue
        } elseif c == "=" or (i + 1 <= strlen and
                _math_or_comp_starter_chars.has(c) and (
                compare_ops.has(str.sub(i, i + 1)) or
                math_ops.has(str.sub(i, i + 1)) or
                math_assign_ops.has(str.sub(i, i + 1)))) {
            # A 2 chars long math, arithmetic math, or assign op!
            # (excluding exponential arithmetic assign "**=")
            var oplen = 2
            if c == "=" and (i + 1 > strlen or
                    str[i + 1] != "=") {
                oplen = 1
            }
            var opstr = str.sub(i, i + oplen - 1)

            # Determine exact token kind
            var kind = T_ASSIGN
            if math_ops.has(opstr) {
                kind = T_MATH
            } elseif compare_ops.has(opstr) {
                kind = T_COMPARE
            } elseif math_assign_ops.has(opstr) {
                kind = T_MATHASSIGN
            }
            result.tokens.add(new Token(
                str.sub(i, i + oplen - 1), kind, line, col
            ))
            col += (oplen - 1)
            i += (oplen - 1)
            continue
        } elseif {"^", "<", ">"}.has(c) and i + 2 <= strlen and
                math_assign_ops.has(str.sub(i, i + 3)) {
            # Special handling of 3 chars arithmetic assigns:
            result.tokens.add(new Token(
                str.sub(i, i + 3), T_MATHASSIGN, line, col
            ))
            i += 2
            col += 2
            continue
        } elseif compare_ops.has(c) {
            # A 1 char compare op.
            result.tokens.add(new Token(c, T_COMPARE, line, col))
            continue
        } elseif math_ops.has(c) {
            # A 1 char math op.
            if c == "-" and (last_nonspace_token == none or
                    is_minus_after_this_token_unary(
                        last_nonspace_token
                    )) {  # Special case of unary '-' operator:
                result.tokens.add(new Token("-", T_UNARYMATH, line, col))
            } else {
                # Regular binary math operator.
                result.tokens.add(new Token(c, T_MATH, line, col))
            }
            continue
        } elseif c == "_" or text.code(c) > 127 or
                (text.code(c) >= code_a and
                text.code(c) <= code_z) or
                (text.code(c) >= code_cap_a and
                text.code(c) <= code_cap_z) or
                (internal_labels and c == '$') {
            # That's an identifier, or keyword, or 'none'.
            var had_nondollar = (c != '$')
            var start_idx = i
            i += 1
            while i <= strlen {
                c = str[i]
                if c == "_" or text.code(c) > 127 or
                        (text.code(c) >= code_a and
                        text.code(c) <= code_z) or
                        (text.code(c) >= code_cap_a and
                        text.code(c) <= code_cap_z) or
                        (text.code(c) >= code_0 and
                        text.code(c) <= code_9) or
                        (internal_labels and c == '$') {
                    if c != '$' {
                        had_nondollar = yes
                    }
                    i += 1
                    continue
                }
                break
            }
            i -= 1
            const name = str.sub(start_idx, i)
            if auto_recovery and
                    _maybe_stmt_token_strs.has(name) and
                    not {"func", "if"}.has(name) {
                guessed_expr_bracket_nesting = []
            }
            if bracket_nesting.len > 0 and
                    _guaranteed_outer_scope_tokens.has(name) {
                var openinfo = bracket_nesting.last()
                result.msgs.add(new msg.FileMsg(
                    "Invalid unexpected keyword '" +
                    c + "', not allowed inside any nesting "
                    "like after unclosed '" +
                    openinfo[1] + "' in line " +
                    openinfo[2].as_str() + ", column " +
                    openinfo[3].as_str(),
                    source_file=project_file,
                    line=line, col=col
                ))
                # Adjust to allow auto-recovery to work from here:
                bracket_nesting = []
            }
            # Block identifiers that are just '$':
            if not had_nondollar {
                result.msgs.add(new msg.FileMsg(
                    "Invalid unexpected internal identifier '" +
                    c + "', can't just consist of '$'",
                    source_file=project_file,
                    line=line, col=col
                ))
            }
            # Determine what exactly it is:
            var kind = T_IDENT
            if name == "none" {
                kind = T_NONE
            } elseif name == "yes" or name == "no" {
                kind = T_BOOL
            } elseif bool_compare_ops.has(name) {
                kind = T_BOOLCOMP
            } elseif name == "new" {
                kind = T_NEWOP
            } elseif is_special_word(name, is_moose64=is_moose64) {
                kind = T_KEYWORD
            }
            result.tokens.add(new Token(
                name, kind, line, col
            ))

            col += name.len - 1
            continue
        } elseif text.code(c) == code_0 and
                i + 1 <= strlen and str[i + 1] == "x" {
            # Hex number. Goes until a char stops fitting.
            var k = i + 2
            while k <= strlen {
                c = str[k]
                if (text.code(c) < code_a or
                        text.code(c) > code_z) and
                        (text.code(c) < code_cap_a or
                         text.code(c) > code_cap_z) and
                        (text.code(c) < code_0 or
                         text.code(c) > code_9) {
                    break
                }
                k += 1
            }
            k -= 1
            var numtoken = str.sub(i, k)
            if k <= i + 2 {
                # Oops, invalid, can't have "0x" with no digits.
                result.msgs.add(new msg.FileMsg(
                    "Invalid unexpected truncated '0x' " +
                    "with not at least one digit following.",
                    source_file=project_file,
                    line=line, col=col
                ))
                numtoken += "0"  # Fix the token to carry on.
            }
            result.tokens.add(new Token(
                numtoken, T_NUM, line, col
            ))
            col += (k - i)
            i = k
            continue
        } elseif (text.code(c) >= code_0 and
                text.code(c) <= code_9) or
                (c == "-" and i < strlen and
                    text.code(str[i + 1]) >= code_0 and
                    text.code(str[i + 1]) <= code_9) {
            # Decimal number. Goes until a char stops fitting.
            var k = i + 1
            var haddot = no
            if c == "-" {
                k += 1
            }
            while k <= strlen {
                c = str[k]
                if c == "." {
                    if haddot or k + 1 > strlen or
                            text.code(str[k + 1]) < code_0 or
                            text.code(str[k + 1]) > code_9 {
                        break
                    }
                    haddot = 1
                } elseif text.code(str[k]) < code_0 or
                        text.code(str[k]) > code_9 {
                    break
                }
                k += 1
            }
            k -= 1
            var numtoken = str.sub(i, k)
            var is_big_num = no
            if bignum.compare_nums(
                    limit.num_max_str,
                    numtoken) < 0 {
                if is_moose64 {
                    is_big_num = yes
                } else {
                    result.msgs.add(new msg.FileMsg(
                        "Invalid unexpected number literal " +
                        numtoken + " exceeds maximum value " +
                        limit.num_max_str + " that "
                        "a Horse64 num can hold.",
                        source_file=project_file,
                        line=line, col=col
                    ))
                }
            } elseif bignum.compare_nums(
                    limit.num_min_str,
                    numtoken) > 0 {
                if is_moose64 {
                    is_big_num = yes
                } else {
                    result.msgs.add(new msg.FileMsg(
                        "Invalid unexpected number literal " +
                        numtoken + " is below minimum value " +
                        limit.num_min_str + " that "
                        "a Horse64 num can hold.",
                        source_file=project_file,
                        line=line, col=col
                    ))
                }
            }
            result.tokens.add(new Token(
                numtoken, if is_big_num (T_BIGNUM) else (T_NUM),
                line, col
            ))
            col += (k - i)
            i = k
            continue
        } else {
            # Oops, we don't know what that is.
            result.msgs.add(new msg.FileMsg(
                "Invalid unexpected character " +
                describe_char_at(str, i,
                    maybe_cutoff_glyph=no),
                source_file=project_file,
                line=line, col=col
            ))
            continue
        }
    }
    return result
}

func tokenize_from_fileobj (
        fobj, project_file=none,
        keep_whitespace=no,
        keep_comments=no,
        apply_preprocessor=no,
        is_moose64=no
        ) {
    assert(apply_preprocessor == yes or
        project_file == none or project_file.project == none)
    var result = new TokensResult()
    var contents = fobj.read(
        amount=climit.max_source_file_size + 1
    )
    later:

    await contents
    if typename(contents) == "bytes" {
        contents = contents.as_str()
    }
    if contents.len >= climit.max_source_file_size + 1 {
        result.msgs.add(new msg.FileMsg(
            "file exceeds maximum size limit of " +
            climit.max_source_file_size +
            " characters",
            project_file=project_file
        ))
        return result
    }
    func apply_preprocessor_if_needed {
        if not apply_preprocessor {
            return later
        }
        var new_contents = preprocessor.preprocess_file(
            project_file.project, project_file, contents,
            is_moose64=is_moose64
        ) later:

        await new_contents
        contents = new_contents
    }
    apply_preprocessor_if_needed() later:
    result = tokenize_str(
        contents, project_file=project_file,
        keep_whitespace=keep_whitespace,
        keep_comments=keep_comments,
        is_moose64=is_moose64
    )
    return result
}

## @func tokenize_file_from_uri
## Parse the file referenced to by the URI to a
## @{tokens result|TokensResult}.
##
## @param source_uri str The URI of the target file.
## @param keep_whitespace bool Whether to keep whitespace tokens
##     (when set to @{yes})
##     or whether to discard them (set to @{no}, the default).
## @param keep_comments bool Whether to keep comment tokens
##     (when set to @{yes})
##     or whether to discard them (set to @{no}, the default).
## @param project_file (none, project.ProjectFile) If the string
##     originates from a known @{project file|project.ProjectFile},
##     specify it here to be set in the resulting diagnostic
##     messages. However, this parameter is optional and you can
##     leave it away as well.
## @param default_to_diskpath bool If set to @{no} (default), a
##     stringthat isn't clearly an URI like `"example.com:443"`
##     will be smartly guessed as either remote or disk path and
##     converted to a full URI.
##     If set to @{yes}, anything not clearly an URI will always
##     be considered a disk path and converted to a `file://`
##     URI.
## @returns TokensResult The resulting tokens and diagnostic
##     messages, like parse errors or warnings.
func tokenize_from_uri(
        source_uri, project_file=none, keep_whitespace=no,
        keep_comments=no, allow_remote=yes,
        default_to_diskpath=no, is_entrypoint=yes,
        force_single_file=no,
        allow_disk_access=yes, allow_vfs_access=no,
        require_detect_project_dir=yes,
        is_moose64=no,
        debug_modules=no, debug_global_storage=no
        ) {
    source_uri = uri.normalize(
        source_uri, guess_nonfiles=(not default_to_diskpath)
    )
    if project_file != none {
        if source_uri == none {
            source_uri = project_file.source_uri
        }
        if source_uri != project_file.source_uri {
            throw new ValueError("If source_uri parameter is "
                "supplied along with the project_file parameter, "
                "the URIs of both have to match.")
        }
    }
    if net.is_uri_remote(source_uri) and not allow_remote {
        throw new PermissionError("Remote URIs not allowed.")
    }
    if project_file == none {
        project_file = new project.ProjectFile(
            source_uri=source_uri,
            is_entrypoint=is_entrypoint,
            force_single_file=force_single_file,
            is_moose64=is_moose64,
            request_debug_modules=debug_modules,
            request_debug_global_storage=debug_global_storage,
        )
    }
    var early_msgs = []
    func ensure_project_if_needed {
        if not require_detect_project_dir {
            return later
        }
        project_file.ensure_project(msgs=early_msgs) later:
        return later
    }
    ensure_project_if_needed() later:
    var do_preprocess = no
    if project_file.project != none {
        project_file.project.allow_disk_access = (
            allow_disk_access
        )
        project_file.project.allow_vfs_access = (
            allow_vfs_access
        )
        if require_detect_project_dir or
                (project_file.project.packages_dir_uri != none and
                 project_file.project.base_dir_uri != none) {
            do_preprocess = yes
        }
    }
    with project_file.open() later as fileobj {
        var result = tokenize_from_fileobj(fileobj,
            project_file=project_file,
            keep_whitespace=keep_whitespace,
            keep_comments=keep_comments,
            apply_preprocessor=do_preprocess,
            is_moose64=is_moose64) later:

        await result
        result.msgs += early_msgs
        return result
    }
}

## Helper function to get the line pos of a token in a given
## list. It is used in token lists by the AST parser to not
## need to use as many boundary checks.
## @returns (num, none) The token's line number if the position
##     is inside the list, @{none} if the position is outside
##     of it.
func get_line(tokens, pos) {
    if pos < 1 {
        return 1
    }
    if pos > tokens.len {
        if tokens.len == 0 {
            return 1
        }
        return tokens[tokens.len].line
    }
    return tokens[pos].line
}

## Helper function to get the column pos of a token in a given list.
## It is used in token lists by the AST parser to not need
## to use as many boundary checks.
## @returns (num, none) The token's column number if the position
##     is inside the list, @{none} if the position is outside of it.
func get_col(tokens, pos) {
    if pos < 1 {
        return 1
    }
    if pos > tokens.len {
        if tokens.len == 0 {
            return 1
        }
        var lasttoken = tokens[tokens.len]
        assert(lasttoken.str != none and lasttoken.str.len > 0)
        return tokens[tokens.len].col + lasttoken.str.len - 1
    }
    return tokens[pos].col
}

