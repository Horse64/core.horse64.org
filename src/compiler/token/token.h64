# @module compiler.token
# Copyright (c) 2020-2022,  ellie/@ell1e & Horse64 Team (see AUTHORS.md).
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#
# Alternatively, at your option, this file is offered under the Apache 2
# license, see accompanied LICENSE.md.


import bignum from core.horse64.org
import io from core.horse64.org
import text from core.horse64.org
import uri from core.horse64.org

import compiler.limit as limit
import compiler.msg as msg
import compiler.project as project


const _math_ops_single_char = {
    "+", "/", "*", "-", "^", "&",
    "|", "~",
}

const math_ops = (
    _math_ops_single_char + {"**"}
)

const math_assign_ops = {
    "+=", "/=", "*=", "-=", "^=", "&=",
    "|=", "**=", "~="
}

const compare_ops = {
    ">", "<", ">=", "<=", "!=", "=="
}

const bool_compare_ops = {
    "and", "or", "not"
}

const _math_or_comp_starter_chars = (
    _math_ops_single_char + {">", "<", "!"}
)

const _maybe_statement_tokens = {
    "while", "do", "func", "for", "with",
    "var", "const", "type", "import", "if",
    "return", "await", "throw",
}

const _guaranteed_outer_scope_tokens = {
    "type", "import",
}

const special_words = {
    "while", "do", "func", "for", "with",
    "var", "const", "type", "import", "if",
    "return", "await", "later", "rescue",
    "finally", "as", "in", "extends",
    "throw", "new", "any", "from", "protect",
    "repeat", "elseif", "else", "and", "or",
    "not", "ignore", "none", "yes", "no",
    "enum"
}

## Check if the given @{str} or @{token|Token} is a label
## representing a Horse64 special keyword or not.
## @returns bool @{Yes|yes} if keyword, otherwise @{no}.
func is_special_word(value) {
    if has_attr(value, "str") {
        return value.kind == T_KEYWORD or
            value.kind == T_BOOL or
            value.kind == T_NONE or
            value.kind == T_BOOLCOMP
    }
    return special_words.has(value)
}

## Check if the given @{str} or @{token|Token} is
## valid in Horse64 for representing a user-defined
## identifier or a built-in keyword.
## @returns bool @{Yes|yes} if valid as identifier or
##   keyword, otherwise @{no}.
func is_identifier_or_keyword(value, internal_labels=no) {
    if has_attr(value, "str") {
        return (value.kind == T_IDENT)
    }
    if value.len == 0 {
        return no
    }
    const code_a = text.code("a")
    const code_z = text.code("z")
    const code_cap_a = text.code("A")
    const code_cap_z = text.code("Z")
    const code_0 = text.code("0")
    const code_9 = text.code("9")
    var c = value[1]
    if c == "_" or text.code(c) > 127 or
            (text.code(c) >= code_a and
            text.code(c) <= code_z) or
            (text.code(c) >= code_cap_a and
            text.code(c) <= code_cap_z) or
            (internal_labels and c == "$") {
        # That's an identifier or keyword.
        var hadnondollar = (c != '$')
        var i = 2
        while i <= value.len {
            c = value[i]
            if (c == "_" or text.code(c) > 127 or
                    (text.code(c) >= code_a and
                    text.code(c) <= code_z) or
                    (text.code(c) >= code_cap_a and
                    text.code(c) <= code_cap_z) or
                    (text.code(c) >= code_0 and
                    text.code(c) <= code_9) or
                    (internal_labels and c == "$")) {
                if c != "$" {
                    hadnondollar = yes
                }
                i += 1
                continue
            }
            return hadnondollar
        }
        return yes
    }
    return no
}

## Reverse all the bracket types known in Horse64 source
## code in the given string to the opposite. E.g. an input
## of `"(]"` will return `")["`. Used by the tokenizer.
func reverse_brackets(value) {
    if typename(value) == "list" and (
            value.len == 0 or
            typename(value[0]) == "str") {
        var result = []
        for bracket in value {
            result.add(reverse_brackets(bracket))
        }
        return result
    }
    if typename(value) != "str" {
        throw new TypeError("value must be bytes or str.")
    }
    var valuenew = ""
    i = 1
    while i <= value.len {
        if value[i] == "(" {
            valuenew += ")"
        } elseif value[i] == "[" {
            valuenew += "]"
        } elseif value[i] == "{" {
            valuenew += "}"
        } elseif value[i] == ")" {
            valuenew += "("
        } elseif value[i] == "]" {
            valuenew += "["
        } elseif value[i] == "}" {
            valuenew += "{"
        } else {
            valuenew += value[i]
        }
        i += 1
    }
    return valuenew
}

## Possible values for @{Token.kind}.
enum TokenKind {
    T_COMMENT
    T_WSPACE
    T_BRACKET
    T_STR
    T_BYTES
    T_NUM
    T_KEYWORD
    T_BOOL
    T_IDENT
    T_NONE
    T_MATH
    T_UNARYMATH
    T_BOOLCOMP
    T_COMPARE
    T_ASSIGN
    T_MATHASSIGN
    T_MAPASSIGN
    T_COMMA
    T_DOT
    T_COLON
}

type Token {
    ## @type num
    var line

    ## @type num
    var col

    ## @type str
    var str

    ## @type TokenKind
    var kind
}

func Token.as_str {
    var t = "Token("
    t += "str=" + describe_token_str(self.str)
    t += ",kind=" + TokenKind.num_label(self.kind)
    if self.line != none {
        t += ",line=" + self.line.as_str()
        if self.col != none {
            t += ",col=" + self.col.as_str()
        }
    }
    return t + ")"
}

func Token.init(str, kind, line, col) {
    self.kind = kind
    self.str = str
    self.line = line
    self.col = col
}

type TokenizeResult {
    ## @type [msg.FileMsg]
    var msgs = []

    ## @type [Token]
    var tokens = []

    ## @types (project.ProjectFile, none)
    var project_file
}

func TokenizeResult.as_json_obj {
    var output = {
        "messages"-> [],
        "tokens"-> [],
    }
    for m in self.msgs {
        var mjson = {
            "message"-> m.message,
            "kind"-> msg.MsgKind.num_label(m.kind),
            "line"-> m.line,
            "col"-> m.col,
            "file"-> none,
        }
        if m.source_file != none {
            mjson["file"] = m.source_file.source_uri
        }
        output["messages"].add(mjson)
    }
    for t in self.tokens {
        output["tokens"].add({
            "str"-> t.str,
            "kind"-> TokenKind.num_label(t.kind),
            "line"-> t.line,
            "col"-> t.col,
        })
    }
    return output
}

func TokenizeResult.as_str {
    var t = "TokenizeResult(tokens=["
    var max_print_tokens = 10
    var i = 1
    while i <= self.tokens.len and i <= max_print_tokens {
        if i > 1 {
            t += ","
        }
        t += self.tokens[i].as_str()
        i += 1
    }
    if self.tokens.len > max_print_tokens {
        t += ",..."
    }
    t += "]),msgs=#" + self.msgs.len.as_str()
    return t + ")"
}

func describe_token_str(s) {
    if is_num(s) {
        return s
    }
    if s.glyph_len <= 1 {
        return describe_char_at(s, 1, maybe_cutoff_glyph=no)
    }
    if s.startswith("'") or s.startswith('"') or
            s.startswith("b'") or s.startswith('b"') {
        return s
    }
    if is_identifier_or_keyword(s) or math_assign_ops.has(s) or
            math_ops.has(s) or s == "=" or compare_ops.has(s) {
        return "'" + s + "'"
    }
    return "<unprintable token>"
}

func describe_char_at(
        s, i, maybe_cutoff_glyph=no
        ) {
    if s == "" or i > s.len or i < 1 {
        return "''"
    }

    var c = s.sub(i, i)
    var codepoint = text.code(c)
    if codepoint >= 32 and codepoint <= 126 {
        # Nice ASCII range, just print it:
        if c == "'" {
            return '"\'"'
        }
        return "'" + c + "'"
    }
    if codepoint < 32 {
        # This is a range we definitely want to escape:
        var result = "'\\x"
        hexstr = text.code(c).as_hex()
        if hexstr.len < 2 {
            result += "0"
        }
        return result + hexstr + "'"
    }
    if codepoint == 127 {
        return "'\\x7F'"
    }

    # If we arrive here it's a multibyte char.

    # See if this is a complete glyph:
    var glyph_indexes = text.glyph_codepoint_len(s, index=i)
    if glyph_indexes <= s.len - i or not maybe_cutoff_glyph {
        # We guaranteed got the full glyph.
        return "'" + s.sub(i, i + 10).glyph_sub(1, 1) + "'"
    }

    # We can't know if we have the full glyph. Better escape:
    var hexstr = text.code(c).as_hex()
    while hexstr.len < 8 {
        hexstr = "0" + hexstr
    }
    return "'\\u" + hexstr + "'"
}

## Escape a string such that it could be written out into a Horse64
## code file again as a single token, by escaping back slashes etc.
func as_escaped_code_string(s, quote_type='"') {
    if quote_type != "'" and quote_type != '"' {
        throw new ValueError("unsupported quote type")
    }

    var new_s = ""
    var i = 1
    while i <= s.len {
        var c = s.sub(i, i)
        var cp = text.code(c)
        if c == "\n" {
            new_s += "\\n"
        } elseif c == "\\r" {
            new_s += "\\r"
        } elseif c == quote_type {
            new_s += "\\" + quote_type
        } elseif cp < 32 {
            var hexstr = text.code(c).as_hex()
            while hexstr.len < 2 {
                hexstr = "0" + hexstr
            }
            new_s += "\\x" + hexstr
        } elseif c == "\\" {
            new_s += "\\\\"
        } else {
            new_s += c
        }
        i += 1
    }
    return quote_type + new_s + quote_type
}

## Tokenize the given Horse64 code string to proper tokens.
## If auto recovery is enabled and the user forgets to close
## brackets or terminate strings, `tokenize_str` might try to
## repair the input and carry on anyway.
##
## @param str str The Horse64 code string to be tokenized.
## @param project_file project.ProjectFile The associated
##     code file for this code string, if any.
## @param auto_recovery bool Whether to try to auto repair after
##     errors to maybe still return a meaningful result. This may
##     improve error output but risks false positive later errors.
func tokenize_str(
        str, project_file=none,
        keep_whitespace=no,
        keep_comments=no,
        auto_recovery=yes,
        internal_labels=no,
        ) {
    var result = TokenizeResult()
    result.project_file = project_file
    var strlen = str.len

    var known_string_escapes = {
        "n", "r", "t", "x", "u", "0",
        "\\", '"', "'"
    }

    const code_a = text.code("a")
    const code_z = text.code("z")
    const code_cap_a = text.code("A")
    const code_cap_z = text.code("Z")
    const code_0 = text.code("0")
    const code_9 = text.code("9")
    var bracket_nesting = []
    var guessed_expr_bracket_nesting = []

    # Process the tokens:
    var line = 1
    var col = 0
    var i = 0
    while i < strlen {
        i += 1
        col += 1
        c = str[i]

        #print("LOOKING AT #" + i.as_str() +
        #    ": " + describe_char_at(
        #    c, 1, maybe_cutoff_glyph=yes) +
        #    " || " + [bracket_nesting,
        #    guessed_expr_bracket_nesting,
        #    result.msgs].as_str())

        if i + 1 < strlen and c == "-" and
                str[i + 1] == ">" {
            # -> map operator
            result.tokens.add(new Token(
                "->", T_MAPASSIGN, line, col
            ))
            i += 1
            col += 1
            continue
        } elseif c == "." {
            # Dot.
            result.tokens.add(new Token(
                ".", T_DOT, line, col
            ))
            continue
        } elseif c == "," {
            # Comma.
            result.tokens.add(new Token(
                ",", T_COMMA, line, col
            ))
            continue
        } elseif c == ":" {
            # Colon.
            result.tokens.add(new Token(
                ":", T_COLON, line, col
            ))
            continue
        } elseif c == "'" or c == '"' or
                (c == "b" and i + 1 < strlen and
                (str[i + 1] == "'" or str[i + 1] == '"')) {
            # Str or bytes literal:
            var start_line = line
            var start_col = col
            var end_marker = c
            var is_bytes = no
            var k = i
            if c == "b" {
                is_bytes = yes
                end_marker = str[i + 1]
                k += 1
                col += 1
            }
            if k + 1 > strlen {
                result.msgs.add(msg.FileMsg(
                    "Unterminated " +
                    if is_bytes ("bytes") else ("string") +
                    " literal.",
                    source_file=project_file,
                    line=start_line, col=start_col
                ))
                result.tokens.add(new Token(
                    if is_bytes ("b") else ("") +
                    end_marker + end_marker,
                    if is_bytes (T_BYTES) else (T_STR),
                    start_line, start_col))
                continue
            }

            # Find the end of the literal:
            var next_escaped = no
            var inner_start_idx = k + 1
            var inner_start_line = line
            var inner_start_col = col + 1
            while k + 1 <= strlen {
                k += 1
                col += 1
                if str[k] == "\r" {
                    col = 0
                    line += 1
                    next_escaped = no
                    if k + 1 < strlen and str[k + 1] == "\n" {
                        k += 1
                        continue
                    }
                } elseif str[k] == "\n" {
                    col = 0
                    line += 1
                    next_escaped = no
                    continue
                }
                if str[k] == "\\" {
                    if next_escaped {
                        next_escaped = no
                        continue
                    }
                    next_escaped = yes
                    if k + 1 < strlen and
                            not known_string_escapes.has(
                            str[k + 1]) {
                        result.msgs.add(msg.FileMsg(
                            "Invalid string escape '\\' + " +
                            describe_char_at(str, k,
                                maybe_cutoff_glyph=no) + ".",
                            source_file=project_file,
                            line=line, col=col
                        ))
                    }
                    continue
                } elseif str[k] == end_marker and
                        not next_escaped {
                    break
                }
                next_escaped = no
            }
            var cutoff = no
            if k > strlen or str[k] != end_marker {
                cutoff = yes
                result.msgs.add(msg.FileMsg(
                    "Unterminated " +
                    if is_bytes ("bytes") else ("string") +
                    " literal.",
                    source_file=project_file,
                    line=start_line, col=start_col
                ))
            }
            if cutoff and auto_recovery and
                    inner_start_idx <= strlen {
                # Try to guess where this literal should have been
                # terminated:
                var inner_string = str.sub(inner_start_idx)
                var inner_tokens_result = tokenize_str(
                    inner_string, keep_whitespace=no,
                    auto_recovery=no
                )
                var inner_tokens =
                    inner_tokens_result.tokens
                var recover_str_offset = none
                var j = 0
                while j < inner_tokens.len {
                    j += 1
                    var stroffset = none
                    if _maybe_statement_tokens.has(
                            inner_tokens[j].str) {
                        # Might be a new statement. Terminate here.
                        recover_str_offset =
                            get_str_offset_from_line_col(
                                inner_string,
                                inner_tokens[j].line,
                                inner_tokens[j].col,
                                start_line=inner_start_line,
                                start_col=inner_start_col
                            )
                        if recover_str_offset != none {
                            break
                        }
                    }
                }
                if recover_str_offset != none {
                    # We got a recovery point. Try to repair:
                    var offset = recover_str_offset
                    var close_brackets_str =
                        guessed_expr_bracket_nesting.join("")
                    close_brackets_str =
                        reverse_brackets(
                        close_brackets_str)

                    # Insert the closing "/' and close all brackets
                    # (at least the brackets we're guessing)
                    str = str.sub(1, offset - 1) +
                        end_marker +
                        close_brackets_str +
                        str.sub(offset)

                    # Set ourselves to the new point and resume:
                    strlen = str.len
                    line = inner_tokens[j].line
                    col = inner_tokens[j].col - 1
                    col += close_brackets_str.len
                    for bracket in
                            guessed_expr_bracket_nesting {
                        if bracket_nesting.len > 0 {
                            bracket_nesting.pop()
                        }
                    }
                }
            }
            result.tokens.add(new Token(
                str.sub(i, k),
                if is_bytes (T_BYTES) else (T_STR),
                start_line, start_col
            ))
            i = k
            continue
        } elseif c == "#" {
            # A line comment:
            start_line = line
            start_col = col
            col += 1
            start_pos = i
            i += 1
            while i < strlen and str[i] != "\n" and
                    str[i] != "\r" {
                col += 1
                i += 1
            }
            col -= 1
            i -= 1
            if keep_comments {
                var comment = str.sub(start_pos, i)
                result.tokens.add(new Token(
                    comment, T_COMMENT, start_line, start_col
                ))
            }
            continue
        } elseif c == " " or c == "\t" or c == "\r" or c == "\n" {
            # Handle whitespace:
            var start_line = line
            var start_col = col
            var whitespace_start = i
            while i <= strlen and (
                    str[i] == " " or str[i] == "\t" or
                    str[i] == "\r" or str[i] == "\n") {
                if str[i] != "\r" and str[i] != "\n" {
                    col += 1
                    i += 1
                } else {
                    col = 1
                    line += 1
                    if str[i] == "\r" and i + 1 <= strlen and
                            str[i + 1] == "\n" {
                        i += 2
                    } else {
                        i += 1
                    }
                }
            }
            col -= 1
            i -= 1
            if keep_whitespace {
                var wspace = str.sub(whitespace_start, i)
                result.tokens.add(new Token(
                    wspace, T_WSPACE, start_line, start_col
                ))
            }
            continue
        } elseif c == "(" or c == "[" or c == "{" {
            # Opening brackets:
            if auto_recovery {
                guessed_expr_bracket_nesting.add(c)
            }
            bracket_nesting.add([c, line, col])
            result.tokens.add(new Token(
                c, T_BRACKET, line, col
            ))
            continue
        } elseif c == ")" or c == "]" or c == "}" {
            # Closing brackets:
            if auto_recovery and
                    guessed_expr_bracket_nesting.len > 0 {
                guessed_expr_bracket_nesting.pop()
            }
            if bracket_nesting.len == 0 {
                result.msgs.add(msg.FileMsg(
                    "Invalid unexpected closing bracket '" +
                    c + "', no brackets left open",
                    source_file=project_file,
                    line=line, col=col
                ))
            } else {
                var reversec = reverse_brackets(c)
                assert(reversec != c)
                var openinfo = bracket_nesting.last()
                if openinfo[1] != reversec {
                    result.msgs.add(msg.FileMsg(
                        "Invalid unexpected closing bracket '" +
                        c + "', expected match for '" +
                        openinfo[1] + "' in line " +
                        openinfo[2].as_str() + ", column " +
                        openinfo[3].as_str(),
                        source_file=project_file,
                        line=line, col=col
                    ))
                }
                bracket_nesting.pop()
            }
            result.tokens.add(new Token(
                c, T_BRACKET, line, col
            ))
            continue
        } elseif c == "=" or (i + 1 <= strlen and
                _math_or_comp_starter_chars.has(c) and (
                compare_ops.has(str.sub(i, i + 1)) or
                math_ops.has(str.sub(i, i + 1)) or
                math_assign_ops.has(str.sub(i, i + 1)))) {
            # A 2 chars long math, arithmetic math, or assign op!
            # (excluding exponential arithmetic assign "**=")
            var oplen = 2
            if c == "=" and (i + 1 > strlen or
                    str[i + 1] != "=") {
                oplen = 1
            }
            var opstr = str.sub(i, i + oplen - 1)

            # Determine exact token kind
            var kind = T_ASSIGN
            if math_ops.has(opstr) {
                kind = T_MATH
            } elseif compare_ops.has(opstr) {
                kind = T_COMPARE
            } elseif math_assign_ops.has(opstr) {
                kind = T_MATHASSIGN
            }
            result.tokens.add(new Token(
                str.sub(i, i + oplen - 1), kind, line, col
            ))
            col += (oplen - 1)
            i += (oplen - 1)
            continue
        } elseif c == "*" and i + 2 <= strlen and
                str.sub(i, i + 3) == "**=" {
            # Special handling of 3 chars arithmetic assign "**=":
            result.tokens.add(new Token(
                "**=", T_MATHASSIGN, line, col
            ))
            i += 2
            col += 2
            continue
        } elseif compare_ops.has(c) {
            # A 1 char compare op.
            result.tokens.add(new Token(c, T_COMPARE, line, col))
            continue
        } elseif math_ops.has(c) {
            # A 1 char math op.
            result.tokens.add(new Token(c, T_MATH, line, col))
            continue
        } elseif c == "_" or text.code(c) > 127 or
                (text.code(c) >= code_a and
                text.code(c) <= code_z) or
                (text.code(c) >= code_cap_a and
                text.code(c) <= code_cap_z) or
                (internal_labels and c == '$') {
            # That's an identifier, or keyword, or 'none'.
            var had_nondollar = (c != '$')
            var start_idx = i
            i += 1
            while i <= strlen {
                c = str[i]
                if c == "_" or text.code(c) > 127 or
                        (text.code(c) >= code_a and
                        text.code(c) <= code_z) or
                        (text.code(c) >= code_cap_a and
                        text.code(c) <= code_cap_z) or
                        (text.code(c) >= code_0 and
                        text.code(c) <= code_9) or
                        (internal_labels and c == '$') {
                    if c != '$' {
                        had_nondollar = yes
                    }
                    i += 1
                    continue
                }
                break
            }
            i -= 1
            const name = str.sub(start_idx, i)
            if auto_recovery and
                    _maybe_statement_tokens.has(
                    name) {
                guessed_expr_bracket_nesting = []
            }
            if bracket_nesting.len > 0 and
                    _guaranteed_outer_scope_tokens.has(name) {
                var openinfo = bracket_nesting.last()
                result.msgs.add(msg.FileMsg(
                    "Invalid unexpected keyword '" +
                    c + "', not allowed inside any nesting "
                    "like after unclosed '" +
                    openinfo[1] + "' in line " +
                    openinfo[2].as_str() + ", column " +
                    openinfo[3].as_str(),
                    source_file=project_file,
                    line=line, col=col
                ))
                # Adjust to allow auto-recovery to work from here:
                bracket_nesting = []
            }
            # Block identifiers that are just '$':
            if not had_nondollar {
                result.msgs.add(msg.FileMsg(
                    "Invalid unexpected internal identifier '" +
                    c + "', can't just consist of '$'",
                    source_file=project_file,
                    line=line, col=col
                ))
            }
            # Determine what exactly it is:
            var kind = T_IDENT
            if name == "none" {
                kind = T_NONE
            } elseif name == "yes" or name == "no" {
                kind = T_BOOL
            } elseif bool_compare_ops.has(name) {
                kind = T_BOOLCOMP
            } elseif is_special_word(name) {
                kind = T_KEYWORD
            }
            result.tokens.add(new Token(
                name, kind, line, col
            ))

            col += name.len - 1
            continue
        } elseif (text.code(c) >= code_0 and
                text.code(c) <= code_9) or
                (c == "-" and i < strlen and
                    text.code(str[i + 1]) >= code_0 and
                    text.code(str[i + 1]) <= code_9) {
            # Decimal number. Goes until a char stops fitting.
            var k = i + 1
            var haddot = no
            if c == "-" {
                k += 1
            }
            while k <= strlen {
                c = str[k]
                if c == "." {
                    if haddot or k + 1 > strlen or
                            text.code(str[k + 1]) < code_0 or
                            text.code(str[k + 1]) > code_9 {
                        break
                    }
                    haddot = 1
                } elseif text.code(str[k]) < code_0 or
                        text.code(str[k]) > code_9 {
                    break
                }
                k += 1
            }
            k -= 1
            var numtoken = str.sub(i, k)
            if bignum.compare_nums(
                    limit.num_max_str,
                    numtoken) < 0 {
                result.msgs.add(msg.FileMsg(
                    "Invalid unexpected number literal " +
                    numtoken + " exceeds maximum value " +
                    limit.num_max_str + " that "
                    "a Horse64 num can hold",
                    source_file=project_file,
                    line=line, col=col
                ))
            } elseif bignum.compare_nums(
                    limit.num_min_str,
                    numtoken) > 0 {
                result.msgs.add(msg.FileMsg(
                    "Invalid unexpected number literal " +
                    numtoken + " is below minimum value " +
                    limit.num_min_str + " that "
                    "a Horse64 num can hold",
                    source_file=project_file,
                    line=line, col=col
                ))
            }
            result.tokens.add(new Token(
                numtoken, T_NUM, line, col
            ))
            col += (k - i)
            i = k
            continue
        } else {
            # Oops, we don't know what that is.
            result.msgs.add(msg.FileMsg(
                "Invalid unexpected character " +
                describe_char_at(str, i,
                    maybe_cutoff_glyph=no),
                source_file=project_file,
                line=line, col=col
            ))
            continue
        }
    }
    return result
}

func tokenize_from_fileobj (
        fobj, project_file=none,
        keep_whitespace=no) {
    var result = new TokenizeResult()
    var contents = fobj.read(
        amount=limit.max_source_file_size + 1
    )
    later:

    await contents
    if contents.len >= limit.max_source_file_size + 1 {
        result.msgs.add(msg.FileMsg(
            "file exceeds maximum size limit of " +
            limit.max_project_file_size +
            " characters",
            project_file=project_file
        ))
        return result
    }
    var result = tokenize_str(
        contents, project_file=project_file,
        keep_whitespace=keep_whitespace
    )
    return result
}

func tokenize_file(
        path, project_file=none,
        keep_whitespace=no
        ) {
    var result = tokenize_file_by_uri(
        uri.from_disk_path(path), project_file=project_file,
        keep_whitespace=keep_whitespace
    ) later:

    await result
    return result
}

func tokenize_file_by_uri(
        source_uri, project_file=none, keep_whitespace=no
        ) {
    source_uri = uri.normalize(source_uri)
    var resource = uri.to_file_or_vfs_path(source_uri)
    var is_vfs = source_uri.lower().startswith("vfs://")
    if project_file == none {
        project_file = project.ProjectFile(
            source_uri=source_uri
        )
    }
    var fileobj = io.open(resource, "r")
    do {
        var result = tokenize_from_fileobj(fileobj,
            project_file=project_file,
            keep_whitespace=keep_whitespace) later:

        await result
        return result
    } finally {
        fileobj.close()
    }
}

